# Click-Through-Rate-in-Twitch-Streaming
The project work is titled "Predicting Click-Through Rate (CTR) in Twitch Streaming". It covers several big data technologies:


Hadoop: A solution for processing large call records to identify phone numbers with over 10 minutes of STD calls and calculate total duration. The implementation uses Hadoop MapReduce for distributed processing and stores data in HDFS.





MongoDB: Utilized for storing and querying Walmart's varied dataset, including sales, inventory, and customer feedback. It aims to provide insights like sales for specific dates, unemployment rates, and holiday sales, enabling real-time analysis and horizontal scaling. Another chapter details MongoDB's use for location-based data management, analyzing geospatial information using aggregation framework operators like in, nin, and union.



Spark: A diagram illustrates a workflow where Tweets undergo data preprocessing (e.g., data cleaning, normalization, tokenization, stemming/lemmatization, TF-IDF) before being fed into Deep Learning Models (LSTM, BERT, GRU). The project includes an accuracy comparison of these models, showing GRU with the highest accuracy at 0.98, followed by LSTM and BERT at 0.95. It also analyzes top tweet locations, sentiment distribution, price discussion trends, frequency of discount mentions, and common slang terms
